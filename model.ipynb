{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:44.003274Z",
     "start_time": "2021-06-13T07:52:41.857901Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from glob import glob as gl\n",
    "import cv2\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:48.892550Z",
     "start_time": "2021-06-13T07:52:44.005343Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet_backbone = ResNet50(weights=\"imagenet\", include_top=False, pooling=None, input_tensor=Input(shape=(224, 224, 3)))\n",
    "backbone_output = resnet_backbone.output\n",
    "\n",
    "# head\n",
    "head = AveragePooling2D(pool_size=(7, 7))(backbone_output)\n",
    "head = Flatten(name=\"flatten\")(head)\n",
    "head = Dense(512, activation=\"relu\")(head)\n",
    "head = Dropout(0.5)(head)\n",
    "head = Dense(512, activation=\"relu\")(head)\n",
    "head = Dropout(0.25)(head)\n",
    "head = Dense(256, activation=\"relu\")(head)\n",
    "head = Dropout(0.25)(head)\n",
    "head = Dense(64, activation=\"relu\")(head)\n",
    "head = Dropout(0.25)(head)\n",
    "head = Dense(1, activation=\"sigmoid\")(head)\n",
    "\n",
    "# head\n",
    "# conv1 = Conv2D(1024, 1, activation='relu', strides=1)(backbone_output)\n",
    "# batch_norm1 = Dropout(0.5)(conv1)\n",
    "\n",
    "# conv2 = Conv2D(512, 1, activation='relu', strides=1)(batch_norm1)\n",
    "# batch_norm2 = Dropout(0.25)(conv2)\n",
    "\n",
    "# conv3 = Conv2D(256, 1, activation='relu', strides=1)(batch_norm2)\n",
    "# batch_norm3 = Dropout(0.25)(conv3)\n",
    "\n",
    "# output = Conv2D(2, 1, activation='relu', strides=1)(batch_norm3)\n",
    "# output = GlobalAveragePooling2D()(output)\n",
    "# output = Activation('softmax')(output)\n",
    "\n",
    "# conv4 = Conv2D(256, 3, activation='relu')(backbone_output)\n",
    "# batch_norm3 = BatchNormalization()(conv4)\n",
    "\n",
    "for layer in resnet_backbone.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:48.903475Z",
     "start_time": "2021-06-13T07:52:48.895800Z"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = \"logs/\"\n",
    "tensor_board = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "loss = BinaryCrossentropy(from_logits=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor=test_loss.name, factor=0.1, patience=3, verbose=1)\n",
    "# early_stopping = EarlyStopping(monitor=test_loss.name, min_delta=0, patience=10, verbose=1)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:48.955042Z",
     "start_time": "2021-06-13T07:52:48.905460Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=resnet_backbone.input, outputs=head)\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:48.961612Z",
     "start_time": "2021-06-13T07:52:48.956637Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut_out(image):\n",
    "    img_height, img_width, _ = image.shape\n",
    "    \n",
    "    cutout_size = np.random.randint(20, 50)\n",
    "    cutout_arr = np.full((cutout_size, cutout_size, 3), 0)\n",
    "    \n",
    "    x = np.random.randint(0, img_width - cutout_size + 1)\n",
    "    y = np.random.randint(0, img_height - cutout_size + 1)\n",
    "    \n",
    "    image[y:y+cutout_size, x:cutout_size+x, :] = cutout_arr\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:48.971806Z",
     "start_time": "2021-06-13T07:52:48.964433Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_blur(img):\n",
    "    prop = np.random.randint(0, 100)/100\n",
    "    if prop > 1-0.5/2:\n",
    "        img = cv2.blur(img,(5,5))\n",
    "    if prop < 0.5/2:\n",
    "        img = cv2.blur(img,(3,3))   \n",
    "    return img\n",
    "\n",
    "def motion_blur(img):\n",
    "    size = np.random.randint(1, 3)\n",
    "    size = 2*size+1\n",
    "    \n",
    "    # generating the kernel\n",
    "    kernel_motion_blur = np.zeros((size, size))\n",
    "    kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "    kernel_motion_blur = kernel_motion_blur / size\n",
    "    \n",
    "    # applying the kernel to the input image\n",
    "    img = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "    \n",
    "    return img\n",
    "\n",
    "BLUR_METHOD = [normal_blur, motion_blur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:48.992845Z",
     "start_time": "2021-06-13T07:52:48.973910Z"
    }
   },
   "outputs": [],
   "source": [
    "fonts = gl('fonts/*')\n",
    "\n",
    "with open('eng_dict.txt', 'r', encoding=\"utf8\") as file:\n",
    "    words = [i.strip() for i in file.readlines()]\n",
    "    \n",
    "def generate_text(min_word, max_word):\n",
    "    text = ''\n",
    "    for i in range(random.randint(min_word, max_word)):\n",
    "        if len(text)< 10:\n",
    "            text += ' ' + words[random.randint(0, 25480)]\n",
    "        else:\n",
    "            text += '{}'.format(random.choice([' ', ' ', '  -  ', ' ', ' ', ' ', ' ', ' '])) + words[random.randint(0, 25480)]\n",
    "    if len(text) != 0:\n",
    "        text += '.'\n",
    "    return text\n",
    "\n",
    "def add_text(image):\n",
    "    img_w, img_h, _ = image.shape\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "    d = ImageDraw.Draw(image)\n",
    "    \n",
    "    start_coord = [random.randint(50, (img_w // 4)*3), random.randint(50, (img_h // 2)+100)]\n",
    "    ''' Get random font '''\n",
    "    font_size = random.randint(15, 60)\n",
    "    text_color = random.choice(['red', 'white', 'green', 'yellow', 'white'])\n",
    "    font = ImageFont.truetype(random.choice(fonts), font_size)\n",
    "\n",
    "    ''' Random words '''\n",
    "    text = generate_text(min_word=5, max_word=18)  # @TODO change this if change font size\n",
    "\n",
    "    ''' Draw text on image '''\n",
    "    d.text(start_coord, text, font=font, fill=text_color)\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:49.002050Z",
     "start_time": "2021-06-13T07:52:48.994408Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(img_name):\n",
    "    img = cv2.imread(img_name)\n",
    "    \n",
    "    label = img_name.split('\\\\')[0].replace('data/extracted_frame/', '').split('/')[0]\n",
    "    if label == 'other':\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "        \n",
    "    # blurring\n",
    "    if np.random.randint(0, 100)/100 > 1-0.5/2: \n",
    "        img = random.choice(BLUR_METHOD)(img)\n",
    "        \n",
    "    # flipping\n",
    "    if np.random.randint(0, 100)/100 > 1-0.5/2: \n",
    "        img = cv2.flip(img, random.choice([0, 1]))\n",
    "        \n",
    "    # add text\n",
    "    if np.random.randint(0, 100)/100 > 1-0.5/2: \n",
    "        img = add_text(img)\n",
    "\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # cut out\n",
    "    if np.random.randint(0, 100)/100 > 1-0.5/2: \n",
    "        img = cut_out(img)\n",
    "        \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:49.010489Z",
     "start_time": "2021-06-13T07:52:49.003581Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_generator(images, batch_size):\n",
    "    '''data generator for fit_generator'''\n",
    "    \n",
    "    n = len(images)\n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        image_data = []\n",
    "        labels = []\n",
    "        for b in range(batch_size):\n",
    "            if i == 0:\n",
    "                np.random.shuffle(images)\n",
    "            image, label = get_data(images[i])\n",
    "\n",
    "            image_data.append(np.array(image))\n",
    "            labels.append(label)\n",
    "            \n",
    "            i = (i + 1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "#         process = []\n",
    "#         for i in range(len(labels)):\n",
    "#             label = labels[i]\n",
    "#             if label == 1:\n",
    "#                 process.append(np.array([0, 1]))\n",
    "#             else:\n",
    "#                 process.append(np.array([1, 0]))\n",
    "#         process = np.array(process)\n",
    "        yield image_data, labels\n",
    "\n",
    "def data_generator_wrapper(images, batch_size):\n",
    "    if batch_size <= 0: return None\n",
    "    return data_generator(images, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:49.042792Z",
     "start_time": "2021-06-13T07:52:49.012060Z"
    }
   },
   "outputs": [],
   "source": [
    "EXTRACTED_FRAME_PATH = [gl('data/extracted_frame/other/*'), gl('data/extracted_frame/wood-making/*')]\n",
    "\n",
    "numb_train1 = int(len(EXTRACTED_FRAME_PATH[0])*0.8)\n",
    "numb_train2 = int(len(EXTRACTED_FRAME_PATH[1])*0.8)\n",
    "\n",
    "train_data = EXTRACTED_FRAME_PATH[0][0:numb_train1] + EXTRACTED_FRAME_PATH[1][0:numb_train2] \n",
    "val_data = EXTRACTED_FRAME_PATH[0][numb_train1:] + EXTRACTED_FRAME_PATH[1][numb_train2:] \n",
    "\n",
    "# data = EXTRACTED_FRAME_PATH[0] + EXTRACTED_FRAME_PATH[1]\n",
    "# np.random.shuffle(data)\n",
    "\n",
    "# fold_data = [data[i:i+675] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:49.046350Z",
     "start_time": "2021-06-13T07:52:49.044336Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(2,6):\n",
    "    \n",
    "#     image, label = get_data(data[-i])\n",
    "#     cv2.imwrite('test-{}-{}.png'.format(i, label), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T07:52:49.051798Z",
     "start_time": "2021-06-13T07:52:49.047902Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "total_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T08:13:50.262019Z",
     "start_time": "2021-06-13T07:52:49.053414Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(data_generator_wrapper(train_data, batch_size),\n",
    "            steps_per_epoch=max(1, len(train_data) // batch_size),\n",
    "            validation_data=data_generator_wrapper(val_data, batch_size),\n",
    "            validation_steps=max(1, len(val_data) // batch_size),\n",
    "            epochs=50,\n",
    "            callbacks=[tensor_board, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T08:13:50.308326Z",
     "start_time": "2021-06-13T07:52:41.917Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print('\\nFold ', i+1)\n",
    "\n",
    "#     temp = fold_data.copy()\n",
    "#     val_data = temp[i]\n",
    "#     temp.pop(i)\n",
    "#     train_data = []\n",
    "#     for fold in temp:\n",
    "#         train_data += fold\n",
    "\n",
    "#     model.fit(data_generator_wrapper(train_data, batch_size),\n",
    "#             steps_per_epoch=max(1, len(train_data) // batch_size),\n",
    "#             validation_data=data_generator_wrapper(val_data, batch_size),\n",
    "#             validation_steps=max(1, len(val_data) // batch_size),\n",
    "#             epochs=12+total_epoch,\n",
    "#             initial_epoch=total_epoch,\n",
    "#             callbacks=[tensor_board, checkpoint])\n",
    "#     total_epoch += 12\n",
    "\n",
    "# #         model.evaluate(data_generator_wrapper(val_data, batch_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T08:13:50.309716Z",
     "start_time": "2021-06-13T07:52:41.920Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T08:13:50.311111Z",
     "start_time": "2021-06-13T07:52:41.923Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for layer in resnet_backbone.layers:\n",
    "#     layer.trainable = True\n",
    "    \n",
    "# try:\n",
    "#     for i in range(10):\n",
    "#         print('\\nFold ', i+1)\n",
    "        \n",
    "#         temp = fold_data.copy()\n",
    "#         val_data = temp[i]\n",
    "#         temp.pop(i)\n",
    "#         train_data = []\n",
    "#         for fold in temp:\n",
    "#             train_data += fold\n",
    "        \n",
    "#         model.fit(data_generator_wrapper(train_data, batch_size),\n",
    "#             steps_per_epoch=max(1, len(train_data) // batch_size),\n",
    "#             validation_data=data_generator_wrapper(val_data, batch_size),\n",
    "#             validation_steps=max(1, len(val_data) // batch_size),\n",
    "#             epochs=10+total_epoch,\n",
    "#             initial_epoch=total_epoch,\n",
    "#               callbacks=[tensor_board, checkpoint, CustomCallback()])\n",
    "#         total_epoch += 10\n",
    "        \n",
    "# #         model.evaluate(data_generator_wrapper(val_data, batch_size))\n",
    "        \n",
    "# except Exception as e:\n",
    "#     if model.crashed:\n",
    "#         print('\\nModel crashed')\n",
    "#     else:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_gen = ImageDataGenerator()\n",
    "\"\"\"\n",
    "Data directory structure\n",
    "img_dir/\n",
    "        class1/\n",
    "        class2/\n",
    "        ....\n",
    "\"\"\"\n",
    "img_dir = 'data/extracted_frame/'\n",
    "validation_generator = data_gen.flow_from_directory(img_dir,\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='binary',\n",
    "                                                    shuffle=False )\n",
    "\n",
    "Y_pred = model.predict(validation_generator, 5260  // 64)\n",
    "super_threshold_indices = Y_pred > 0.5\n",
    "Y_pred[super_threshold_indices] = 1\n",
    "\n",
    "super_threshold_indices = Y_pred < 0.5\n",
    "Y_pred[super_threshold_indices] = 0\n",
    "# # y_pred = np.argmax(Y_pred, axis=1) # for categorical data\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, Y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['Other', 'Wood-making']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel",
   "language": "python",
   "name": "kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
